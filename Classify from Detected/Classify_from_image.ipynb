{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import all the libraries used for the program\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import cvlib as cv\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "from keras.utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected in the image:  8\n"
     ]
    }
   ],
   "source": [
    "# reading image from the path\n",
    "image = cv2.imread('full size images\\\\group.jpg')\n",
    "# detecting faces using open-cv\n",
    "faces, _ = cv.detect_face(image)\n",
    "\n",
    "print(\"Number of faces detected in the image: \",len(faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the classification model from the path\n",
    "\n",
    "model_path = os.path.join(os.path.dirname(os.getcwd()),'Train Classifier\\\\3-conv-95.h5')\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes image and the coordinates of faces and model as input\n",
    "# and returns the image with marked faces and label the gender of faces\n",
    "\n",
    "def markFace(faces, image, model):\n",
    "    classes = ['man', 'woman']\n",
    "    if len(faces) == 0:\n",
    "        return image\n",
    "    \n",
    "    for face in faces:\n",
    "         # get corner points of face rectangle       \n",
    "        (startX, startY) = face[0], face[1]\n",
    "        (endX, endY) = face[2], face[3]\n",
    "\n",
    "        # crop the detected face region\n",
    "        face_crop = np.copy(image[startY:endY,startX:endX])\n",
    "\n",
    "        # preprocessing for gender detection model\n",
    "        face_crop = cv2.resize(face_crop, (150,150))\n",
    "        face_crop = face_crop / 255.0\n",
    "        face_crop = np.reshape(face_crop,(1,150,150,3))\n",
    "\n",
    "        # predicting the gender of the cropped face\n",
    "        conf = model.predict(face_crop)[0][0]\n",
    "\n",
    "        # get label of the image\n",
    "        idx = int(np.round(conf))\n",
    "        label = classes[idx]\n",
    "\n",
    "        # get the amount of confidence in the prediction\n",
    "        confid = conf if idx == 1 else 1-conf\n",
    "\n",
    "        label = \"{}: {:.2f}%\".format(label, confid * 100)\n",
    "\n",
    "\n",
    "        # if there is no space above rectangle then write below\n",
    "        Y = startY - 10 if startY - 10 > 10 else endY + 10\n",
    "\n",
    "        # draw rectangle over face\n",
    "        cv2.rectangle(image, (startX,startY), (endX,endY), (0,255,0), 2)\n",
    "        # write label and confidence above face rectangle\n",
    "        fontScale = (endX-startX)/(35/0.15)\n",
    "        if fontScale < 0.5: fontScale = 0.5\n",
    "        cv2.putText(image, label, (startX, Y),  cv2.FONT_HERSHEY_SIMPLEX, fontScale, (0, 255, 0), 2)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling markFace function on the given image\n",
    "image = markFace(faces, image, model)\n",
    "\n",
    "# showing output image in terminal\n",
    "cv2.imshow(\"output\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "# save image\n",
    "cv2.imwrite(\"output image\\\\group.jpg\", image)\n",
    "\n",
    "# release resources\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
